{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_train_ref_data = pd.read_csv('normal_train_ref_data.csv')\n",
    "normal_train_fbk_data = pd.read_csv('normal_train_fbk_data.csv')\n",
    "abnormal_train_ref_data = pd.read_csv('abnormal_train_ref_data.csv')\n",
    "abnormal_train_fbk_data = pd.read_csv('abnormal_train_fbk_data.csv')\n",
    "\n",
    "normal_valid_ref_data = pd.read_csv('normal_valid_ref_data.csv')\n",
    "normal_valid_fbk_data = pd.read_csv('normal_valid_fbk_data.csv')\n",
    "abnormal_valid_ref_data = pd.read_csv('abnormal_valid_ref_data.csv')\n",
    "abnormal_valid_fbk_data = pd.read_csv('abnormal_valid_fbk_data.csv')\n",
    "\n",
    "normal_test_ref_data = pd.read_csv('normal_test_ref_data.csv')\n",
    "normal_test_fbk_data = pd.read_csv('normal_test_fbk_data.csv')\n",
    "abnormal_test_ref_data = pd.read_csv('abnormal_test_ref_data.csv')\n",
    "abnormal_test_fbk_data = pd.read_csv('abnormal_test_fbk_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataframe (Normal + Abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dict = dict()\n",
    "\n",
    "for i in zip(normal_train_ref_data.columns, normal_train_fbk_data.columns):\n",
    "    \n",
    "    a = list(normal_train_ref_data[i[0]][~normal_train_ref_data[i[0]].isna()])\n",
    "    b = max(a)\n",
    "    c = a.index(b)\n",
    "    d = len(a) - a[::-1].index(b)\n",
    "    e = list(normal_train_fbk_data[i[1]][~normal_train_fbk_data[i[1]].isna()])\n",
    "    \n",
    "    unloading_earlier = e[:c]\n",
    "    loading = e[c:d]\n",
    "    unloading_latter = e[d:]\n",
    "    \n",
    "    for k in [('unloading_earlier', unloading_earlier), ('loading', loading), ('unloading_latter', unloading_latter)]:\n",
    "        \n",
    "        for j in [np.min, np.max, np.mean, np.std, kurtosis, skew]:\n",
    "            function_name = j.__name__\n",
    "            try:\n",
    "                train_dict[str(k[0]) + str('_') + str(function_name)] = train_dict[str(k[0]) + str('_') + str(function_name)] + [round(j(k[1]),3)]\n",
    "            except:\n",
    "                train_dict.update({str(k[0]) + str('_') + str(function_name) : [round(np.mean(k[1]),3)]})\n",
    "\n",
    "        for j in [25,50,75]:\n",
    "            try:\n",
    "                train_dict[str(k[0]) + '_percentile' + str(j)] = train_dict[str(k[0]) + '_percentile' + str(j)] + [round(np.percentile(k[1],j),3)]\n",
    "            except:\n",
    "                train_dict.update({str(k[0]) + '_percentile' + str(j) : [round(np.percentile(k[1],j),3)]})\n",
    "                \n",
    "normal_train_df = pd.DataFrame(train_dict)\n",
    "normal_train_df['condition'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dict = dict()\n",
    "\n",
    "for i in zip(abnormal_train_ref_data.columns, abnormal_train_fbk_data.columns):\n",
    "    \n",
    "    a = list(abnormal_train_ref_data[i[0]][~abnormal_train_ref_data[i[0]].isna()])\n",
    "    b = max(a)\n",
    "    c = a.index(b)\n",
    "    d = len(a) - a[::-1].index(b)\n",
    "    e = list(abnormal_train_fbk_data[i[1]][~abnormal_train_fbk_data[i[1]].isna()])\n",
    "    \n",
    "    unloading_earlier = e[:c]\n",
    "    loading = e[c:d]\n",
    "    unloading_latter = e[d:]\n",
    "    \n",
    "    for k in [('unloading_earlier', unloading_earlier), ('loading', loading), ('unloading_latter', unloading_latter)]:\n",
    "        \n",
    "        for j in [np.min, np.max, np.mean, np.std, kurtosis, skew]:\n",
    "            function_name = j.__name__\n",
    "            try:\n",
    "                train_dict[str(k[0]) + str('_') + str(function_name)] = train_dict[str(k[0]) + str('_') + str(function_name)] + [round(j(k[1]),3)]\n",
    "            except:\n",
    "                train_dict.update({str(k[0]) + str('_') + str(function_name) : [round(np.mean(k[1]),3)]})\n",
    "\n",
    "        for j in [25,50,75]:\n",
    "            try:\n",
    "                train_dict[str(k[0]) + '_percentile' + str(j)] = train_dict[str(k[0]) + '_percentile' + str(j)] + [round(np.percentile(k[1],j),3)]\n",
    "            except:\n",
    "                train_dict.update({str(k[0]) + '_percentile' + str(j) : [round(np.percentile(k[1],j),3)]})\n",
    "                \n",
    "abnormal_train_df = pd.DataFrame(train_dict)\n",
    "abnormal_train_df['condition'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([normal_train_df, abnormal_train_df])\n",
    "train_X = train_df.iloc[:,:-1]\n",
    "train_Y = np.array(train_df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dict = dict()\n",
    "\n",
    "for i in zip(normal_valid_ref_data.columns, normal_valid_fbk_data.columns):\n",
    "    \n",
    "    a = list(normal_valid_ref_data[i[0]][~normal_valid_ref_data[i[0]].isna()])\n",
    "    b = max(a)\n",
    "    c = a.index(b)\n",
    "    d = len(a) - a[::-1].index(b)\n",
    "    e = list(normal_valid_fbk_data[i[1]][~normal_valid_fbk_data[i[1]].isna()])\n",
    "    \n",
    "    unloading_earlier = e[:c]\n",
    "    loading = e[c:d]\n",
    "    unloading_latter = e[d:]\n",
    "    \n",
    "    for k in [('unloading_earlier', unloading_earlier), ('loading', loading), ('unloading_latter', unloading_latter)]:\n",
    "        \n",
    "        for j in [np.min, np.max, np.mean, np.std, kurtosis, skew]:\n",
    "            function_name = j.__name__\n",
    "            try:\n",
    "                valid_dict[str(k[0]) + str('_') + str(function_name)] = valid_dict[str(k[0]) + str('_') + str(function_name)] + [round(j(k[1]),3)]\n",
    "            except:\n",
    "                valid_dict.update({str(k[0]) + str('_') + str(function_name) : [round(np.mean(k[1]),3)]})\n",
    "\n",
    "        for j in [25,50,75]:\n",
    "            try:\n",
    "                valid_dict[str(k[0]) + '_percentile' + str(j)] = valid_dict[str(k[0]) + '_percentile' + str(j)] + [round(np.percentile(k[1],j),3)]\n",
    "            except:\n",
    "                valid_dict.update({str(k[0]) + '_percentile' + str(j) : [round(np.percentile(k[1],j),3)]})\n",
    "                \n",
    "normal_valid_df = pd.DataFrame(valid_dict)\n",
    "normal_valid_df['condition'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dict = dict()\n",
    "\n",
    "for i in zip(abnormal_valid_ref_data.columns, abnormal_valid_fbk_data.columns):\n",
    "    \n",
    "    a = list(abnormal_valid_ref_data[i[0]][~abnormal_valid_ref_data[i[0]].isna()])\n",
    "    b = max(a)\n",
    "    c = a.index(b)\n",
    "    d = len(a) - a[::-1].index(b)\n",
    "    e = list(abnormal_valid_fbk_data[i[1]][~abnormal_valid_fbk_data[i[1]].isna()])\n",
    "    \n",
    "    unloading_earlier = e[:c]\n",
    "    loading = e[c:d]\n",
    "    unloading_latter = e[d:]\n",
    "    \n",
    "    for k in [('unloading_earlier', unloading_earlier), ('loading', loading), ('unloading_latter', unloading_latter)]:\n",
    "        \n",
    "        for j in [np.min, np.max, np.mean, np.std, kurtosis, skew]:\n",
    "            function_name = j.__name__\n",
    "            try:\n",
    "                valid_dict[str(k[0]) + str('_') + str(function_name)] = valid_dict[str(k[0]) + str('_') + str(function_name)] + [round(j(k[1]),3)]\n",
    "            except:\n",
    "                valid_dict.update({str(k[0]) + str('_') + str(function_name) : [round(np.mean(k[1]),3)]})\n",
    "\n",
    "        for j in [25,50,75]:\n",
    "            try:\n",
    "                valid_dict[str(k[0]) + '_percentile' + str(j)] = valid_dict[str(k[0]) + '_percentile' + str(j)] + [round(np.percentile(k[1],j),3)]\n",
    "            except:\n",
    "                valid_dict.update({str(k[0]) + '_percentile' + str(j) : [round(np.percentile(k[1],j),3)]})\n",
    "                \n",
    "abnormal_valid_df = pd.DataFrame(valid_dict)\n",
    "abnormal_valid_df['condition'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.concat([normal_valid_df, abnormal_valid_df])\n",
    "valid_X = valid_df.iloc[:,:-1]\n",
    "valid_Y = np.array(valid_df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = dict()\n",
    "\n",
    "for i in zip(normal_test_ref_data.columns, normal_test_fbk_data.columns):\n",
    "    \n",
    "    a = list(normal_test_ref_data[i[0]][~normal_test_ref_data[i[0]].isna()])\n",
    "    b = max(a)\n",
    "    c = a.index(b)\n",
    "    d = len(a) - a[::-1].index(b)\n",
    "    e = list(normal_test_fbk_data[i[1]][~normal_test_fbk_data[i[1]].isna()])\n",
    "    \n",
    "    unloading_earlier = e[:c]\n",
    "    loading = e[c:d]\n",
    "    unloading_latter = e[d:]\n",
    "    \n",
    "    for k in [('unloading_earlier', unloading_earlier), ('loading', loading), ('unloading_latter', unloading_latter)]:\n",
    "        \n",
    "        for j in [np.min, np.max, np.mean, np.std, kurtosis, skew]:\n",
    "            function_name = j.__name__\n",
    "            try:\n",
    "                test_dict[str(k[0]) + str('_') + str(function_name)] = test_dict[str(k[0]) + str('_') + str(function_name)] + [round(j(k[1]),3)]\n",
    "            except:\n",
    "                test_dict.update({str(k[0]) + str('_') + str(function_name) : [round(np.mean(k[1]),3)]})\n",
    "\n",
    "        for j in [25,50,75]:\n",
    "            try:\n",
    "                test_dict[str(k[0]) + '_percentile' + str(j)] = test_dict[str(k[0]) + '_percentile' + str(j)] + [round(np.percentile(k[1],j),3)]\n",
    "            except:\n",
    "                test_dict.update({str(k[0]) + '_percentile' + str(j) : [round(np.percentile(k[1],j),3)]})\n",
    "                \n",
    "normal_test_df = pd.DataFrame(test_dict)\n",
    "normal_test_df['condition'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = dict()\n",
    "\n",
    "for i in zip(abnormal_test_ref_data.columns, abnormal_test_fbk_data.columns):\n",
    "    \n",
    "    a = list(abnormal_test_ref_data[i[0]][~abnormal_test_ref_data[i[0]].isna()])\n",
    "    b = max(a)\n",
    "    c = a.index(b)\n",
    "    d = len(a) - a[::-1].index(b)\n",
    "    e = list(abnormal_test_fbk_data[i[1]][~abnormal_test_fbk_data[i[1]].isna()])\n",
    "    \n",
    "    unloading_earlier = e[:c]\n",
    "    loading = e[c:d]\n",
    "    unloading_latter = e[d:]\n",
    "    \n",
    "    for k in [('unloading_earlier', unloading_earlier), ('loading', loading), ('unloading_latter', unloading_latter)]:\n",
    "        \n",
    "        for j in [np.min, np.max, np.mean, np.std, kurtosis, skew]:\n",
    "            function_name = j.__name__\n",
    "            try:\n",
    "                test_dict[str(k[0]) + str('_') + str(function_name)] = test_dict[str(k[0]) + str('_') + str(function_name)] + [round(j(k[1]),3)]\n",
    "            except:\n",
    "                test_dict.update({str(k[0]) + str('_') + str(function_name) : [round(np.mean(k[1]),3)]})\n",
    "\n",
    "        for j in [25,50,75]:\n",
    "            try:\n",
    "                test_dict[str(k[0]) + '_percentile' + str(j)] = test_dict[str(k[0]) + '_percentile' + str(j)] + [round(np.percentile(k[1],j),3)]\n",
    "            except:\n",
    "                test_dict.update({str(k[0]) + '_percentile' + str(j) : [round(np.percentile(k[1],j),3)]})\n",
    "                \n",
    "abnormal_test_df = pd.DataFrame(test_dict)\n",
    "abnormal_test_df['condition'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([normal_test_df, abnormal_test_df])\n",
    "test_X = test_df.iloc[:,:-1]\n",
    "test_Y = np.array(test_df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "logistic_regression_model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.589595335931625"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC(kernel='poly', C=1e5, degree=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100000.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=1, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "randomForest = ensemble.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest.score(test_X, test_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
